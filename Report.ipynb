{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yytPXQRfS7u6"
      },
      "source": [
        "# Brainbox Group 15 Joint Project Report \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT17ej96L5Vi"
      },
      "source": [
        "# Executive Summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jcIQNCciLCb"
      },
      "source": [
        "The problem that our project addressed is centered around creating a new way to play games hands-free, contributing to the innovations made in the gaming industry in recent years. By engaging this in task, we aim to address two current issues:\n",
        " \n",
        "\n",
        "*   Decreasing the level of contact in gaming by decreasing the use of keyboards and joysticks in a covid-19 context.\n",
        "*   Enabling individuals with physical disabilities to also interact with games.\n",
        "\n",
        "Our team devised a solution; to integrate the classification of eye movements from spikerbox technology and sound from microphone inputs into a space-invaders game. This solution involved a detailed analysis on time series wave data in order to render the desired outputs. Our main findings saw the simple classifier working the best for actual left right classification, whereas machine learning was unable to differentiate between left and right eye movements but was robust towards blinks and noisy data. In analysing the various cross validated classification accuracy results and latency tests on both training and live test data, The practicality of such analysis was clearly demonstrated in vastly improved playability with accurate and responsive real time classifications and this analysis is relevant in evaluating performance of all future games requiring similar streaming inputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI1pFsrZNIYa"
      },
      "source": [
        "# Aim and Background\n",
        "\n",
        "The gaming industry is growing exponentially and thus far, has largely failed to accommodate everyone in their capacities. Individuals with disabilities, specifically those affecting motor function, are left without gaming apparatus that is suited for their needs. This project aims at giving these individuals the opportunity to participate in the gaming revolution by using spikerbox technology to read their eye movements and translate their intentions to game commands. Using the game Space Invaders, we can demonstrate this technology by translating left and right eye movements, allowing the player to move the ship in discrete horizontal intervals. Additionally, a microphone is used to allow the player to shoot a laser beam down the lane the ship is currently in.\n",
        "\n",
        "Our aim is to achieve a space invaders game controlled with voice and eye movement, completely replicating the experience users get when using traditional controls. This includes a reasonable eye movement classification accuracy and low latency for smooth movement.\n",
        "\n",
        "Classifying eye movements is the core challenge of this project, and in order to gauge the most effective approach, a number of classifiers were developed. First, a multinomial logistic regression classifier capable of differentiating blinks, left, and right movements, and second, a simple rule based classifier using wave output standard deviation to recognise movements, and peak identification to distinguish movements. These models were tested with both filtered and raw data, were tested to achieve our goal of a working Space Invaders game with high accuracy and low latency control using the eyes and the voice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt3QvXE6OIKn"
      },
      "source": [
        "# Methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDh-2JrwvZOW"
      },
      "source": [
        "## Data Collection\n",
        "\n",
        "In order to facilitate data collection for training and testing possible models, a python program was written to record signals from the brainbox tech and name the file according to the eye movement it represents. The flexibility of this program allowed for tweaking of parameters such as signal length and filtering settings. As a result, it was an easy task to collect a large variety of data which is balanced. This would be used for model training and accuracy analysis.\n",
        "\n",
        "To collect the data, two electrodes were placed above the participant’s right eye; one near the temple, and the other in line with the edge of the nose, where the two identical red wires are attached. Another electrode was attached behind the participant's ear on the mastoid process, where the black ground wire is connected. After the participant was connected to the spikerbox, we collected balanced eye movement data containing single examples of blinks, left and right movements. We collected raw data from multiple people on different occasions to create a variety of different potential player scenarios, while controlling the positioning of the electrodes, the movements from the eye and ensuring the spikerboxes were giving a correct signal before conducting the data collection.\n",
        "\n",
        "We noticed throughout the data collection and product development stages, that the spikerboxes we used tended to be temperamental, presenting a challenge to produce reliable and consistent results between different boxes and on different occasions. This was often fixed with the replacement of a battery, the slight changing of positioning in the electrodes, or restarting the program, but we regularly resorted to changing boxes in order to get better results. This was a large challenge in the project, but we eventually managed to collect data for training and testing our proposed models of spiker classification.\n",
        "\n",
        "In addition to eye movement data, our program also implemented audio inputs from the participant’s voice using the computer’s embedded microphone. The goal for our final game was for the participant to make a specific sound which triggered the game to shoot. We collected a variety of everyday sounds such as whistling, humming and regular words such as “shoot” to test our potential microphone classifiers. Within each test participant stood 30-50cm away from the inbuilt microphone which was varied throughout the data collection process, but we attempted to control background noise to a minimum during these recordings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4YZy4R2vOja"
      },
      "source": [
        "## Developed Models\n",
        "\n",
        "The live framework of data collection and processing involved setting up the participant in the same controlled way that we used to collect the training data, and real-time inputs simultaneously from both the spikerbox and the computer microphone. These signals were stored in separate window arrays in the code, and the processing of each signal to determine the game movements was done separately.\n",
        "\n",
        "The eye movement data would be put through any filters before being processed by a movement detector, followed by a classifier with an ‘L’ or ‘R’ output. In theory, the filters would help the classifiers easily identify movements, the movement detector would determine if there had been an eye movement in the window, and the classifier would identify which direction the eye moved in, left or right. We experimented with each step in this model to attempt to produce the best outcome based on our evaluation strategies. In addition to this, we have a calibration step to organise the orientation of the red wires, so that the signals remain consistent throughout different setups of the device.\n",
        "\n",
        "The microphone data was processed with a separate classifier. We utilised an amplitude detector, so that a participant saying the word “shoot” triggers an audio threshold volume, telling the game to shoot. In the final product, we also include a calibration of the voice before the game, so that the amplitude threshold is set to the right volume.\n",
        "\n",
        "To assist the spiker classifiers in interpreting left and right eye movements, we implemented a notch filter for the 50 Hz power outlet signal, as well as high and low pass Butterworth filters for removing noise. To calibrate the best frequency range for the filters, we tested qualitatively by looking at the eye movement signal from pre-recorded data and assessing which filtered signal gives the most identifiable signal to the human eye. It was decided that the best signal was given using the 50 Hz notch filter and the frequency range of 3-40 Hz. These filters were both applied to the different classifiers, and the accuracy of each was quantitatively tested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFkOGyPyvHp1"
      },
      "source": [
        "### Logistic Regression\n",
        "In order to classify the signals received from the user, a multinomial logistic regression classifier was trained to predict left-right movements and blinks. To increase the accuracy of this classifier, it was necessary to perform feature selection on the list of time series features which were available. The following features were found to have the highest correlation: flat spots, crossing points, autocorrelation features, mean, and standard deviation.\n",
        "\n",
        "Feature selection included performing Lasso regression followed by a manual selection. Lasso regression introduces a l1 penalty on the loss function, forcing the least-contributing features’ coefficients to zero. This addresses potential issues of multicollinearity by shrinking one of the two highly-correlated features to zero. As a result, the classifier should have better chances of classifying waves with varying noise levels. \n",
        "\n",
        "As a way to correct overfitting, L2 regularisation (Ridge) was used. Due to the nature of the data, this penalty was chosen to combat the unpredictable and sporadic noise levels. Using this penalty in addition to feature selection is an extra measure of reducing the effects of both noise and irrelevant predictors, effectively making the classifier more robust to the varying features of the incoming waves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ow9fNzu_ml"
      },
      "source": [
        "### Simple Classifier\n",
        "In order to gauge the most effective classification method, a simple rule based classifier was developed to compare with the machine learning classifier. This classifier simply took in a wave and identified the amplitude peaks, noting down the order of which they appear. Due to the unreliability of the spikerbox technology, it was common for there to be random spikes in wave amplitude throughout the waves. These were taken into consideration and the proposed solution was to choose the pair of peaks (i.e., positive and negative) with the smallest distance between them. It was found to be highly unlikely for these spikes to appear in close proximity to each other, let alone a negative followed by a positive, or vice versa. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkNvcuDxu7X7"
      },
      "source": [
        "## Evaluation Strategies\n",
        "\n",
        "Evaluation strategies employed by the team included accuracy and latency analysis. Model accuracy evaluation techniques included 4-fold cross-validation and computing a confusion matrix for a random train-test split. Using these strategies, we were able to conduct a number of experiments to determine an ideal value for inverse regularisation strength and test if a simple rule-based classifier would yield more accurate results. \n",
        "\n",
        "One of the main qualitative metrics from a physics perspective is the latency between the classification of a movement to the register of a movement within the space invaders game. This involved using the time.time() funtion in python to ensure that we could capture the latencies of both classifiers when implemented within the game. The latencies of the figures were then plotted out using the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-tfRrfOOlAL",
        "outputId": "b70a8df3-f682-488d-f81d-19c252a90089"
      },
      "source": [
        "<img src=\"./LR_accuracy.PNG\">\n",
        "\n",
        "*Figure 1. Logistic Regression Classification Accuracy*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk9MQfQpmwvB"
      },
      "source": [
        "Figure 1 shows that the average accuracy of the multinomial regression classifier was around 66 +/- 10 % for unfiltered waves. The filtered wave accuracy was around 42% (See [Appendix C](#Appendix-C)). On the other hand, the simple classifier accuracy was found to be 75% on 109 unfiltered samples and 38% on filtered waves. See [Appendix E](#Appendix-E) for a confusion matrix of simple classifier accuracy. While the obvious advantage of multinomial regression is the ability to handle blinks, the simple classifier was chosen as the main model for two reasons. Firstly, it had significantly better left-right movement performance, which is crucial for optimal user experience. Secondly, it did not require pre-training and produced predictions faster, which was particularly desirable under streaming conditions, where a rapid response was required as the difficulty level increased.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za67d8DMPYLm"
      },
      "source": [
        "### Qualitative Evaluation\n",
        "Another way to evaluate the effectiveness of this model is to analyse the simple classification latency. Here, we define latency as the time it takes between the moment a signal is registered from the spikerbox to the moment it is classified (essentially, to the moment the game ship responds).Since the success of this software relies on the user being able to easily play Space Invaders, this evaluation metric is highly relevant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqRdtDZyPwaX"
      },
      "source": [
        "<img src=\"./latency_graph.png\">\n",
        "\n",
        "*Figure 2. Classification Latency* [Appendix C](#Appendix-C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daL0gu90bgly"
      },
      "source": [
        "The above graph shows the latency over a minute of gameplay with numerous movements, which are undistinguishable, where the red line represents 3 standard deviations away from the mean latency, thus everything below the red line represents 99.7% of all latencies. Since the standard deviation of these results was approximately 5 milliseconds (see [Appendix B](#Appendix-B)), there was no noticable effect on latency regardless of any eye movement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NjIGDiPP0kT"
      },
      "source": [
        "Two factors which were believed to greatly influence the classifier accuracy, were window size and overlap. Below is a boxplot representing the accuracy of varying window sizes, for half overlapping windows and zero-overlap windows, on three pre-recorded live data samples of length 1 minute each. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqxfGuBWP_4W"
      },
      "source": [
        "<img src=\"./windows.png\">\n",
        "\n",
        "*Figure 3. Accuracy across varying window sizes and overlap factors*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVHR8rSnbgl0"
      },
      "source": [
        "First point to notice is that all accuracies for half overlapping windows are negative. The reason for this is due to the lack of a robust accuracy measurement function. Levenschtein distance was used to compare the predicted labels (as a string) with the true labels (as a string). However, since using half overlapping windows producing twice as many windows with potential movements, it is more likely that there will be a classification. Thus the predicted labels string will be much longer than the actual labels. The accuracy computation is as follows:\n",
        "\n",
        "`( (length(true_labels) - levenschtein_distance(predicted, true)) / length(true_labels) ) * 100`\n",
        "\n",
        "The second point to note is that the logistic regression (LR) classifier and simple rule based classifier were used in conjunction. Considering the LR classifier was robust to blinks (and other noise), but was not able to distinguish left and right, the simple rule based classifier was tasked with classifying all that is not predicted as blinking (or noise).\n",
        "\n",
        "Third point to note is that these accuracies were averaged over results from 3 different 1 minutes waves. Upon inspection into the results of the code in [Appendix C](#Appendix-C), it was found that the standard deviation between each recording, for both overlapping types, was quite large (Please refer to [Appendix D](#Appendix-D)).\n",
        "\n",
        "From this graph, it can be seen that no overlap between windows and 2 second long windows yielded the best accuracy. Thus, in the final product the new data read in from the spikerbox was stored until 2 seconds worth of data was ready to be analysed and no overlapping windows were considered. However, this produced the undesirable effect of sluggish movements as the game would only let you move every 2 seconds. As a result, this value was reduced down to 1 second and this was the final parameter setting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryxpzTM4OmLh"
      },
      "source": [
        "# Results\n",
        "\n",
        "Our final product begins with the option to calibrate the eye movement, and a calibration of the amplitude detector for the microphone input. The participant is asked to make 5 left movements, followed by 5 noises they will use to shoot. Following this the game begins, with the participant’s left/right eye movements controlling the player’s left/right movement, and their voice controlling the shooting of the player.\n",
        "\n",
        "From the proposed evaluation strategies, the final approach entailed the simple rule based classifier which analysed the peaks of the raw waves. Despite training a logistic regression model and conducting experiments to derive the most effective parameter tunings, this solution was decided on as the livestreaming classification results were just more accurate. The reason for this is believed to be a difference in the processing of the training data and the live input data.\n",
        "\n",
        "The filtered data also turned out to be less accurate than the raw eye movement data, as with a reliable spikerbox, the signal was really obvious and easy to detect with the simple classifier.\n",
        "\n",
        "Our final spiker classifier accuracy on pre-recorded data was (75 +/- 4)%, whereas in the real-time conditions, it classified 18/20 eye movements correctly, giving around (90 +/- 7)% accuracy.\n",
        "\n",
        "Additionally, the microphone amplitude detector accuracy was measured to be (98 +/- 1)% (See [Appendix F](#Appendix-F))\n",
        "\n",
        "![diagram](https://drive.google.com/uc?export=view&id=1y8C8-IG3Z6LjvjPo5qo8xv9GAGRI-8fI)\n",
        "\n",
        "*Figure 4. Deployment Pipeline Flowchart.*\n",
        "\n",
        "![diagram](https://drive.google.com/uc?export=view&id=1SBz9vOgjFeDRuny2u2OLQkH1SYTDNLxe)\n",
        "\n",
        "*Figure 5. Gameplay image*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDXRZ9T9Q2mI"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "There was a period in the beginning where the students from both disciplines lacked synchronisation in that knowledge barriers were yet to be broken (Bronstein, 2003). Once team discussions had taken place, and the goals of the project were laid out, our team had aligned viewpoints allowing us to break down tasks and delegate accordingly (Shapiro, 2008). \n",
        "\n",
        "## Shortcomings\n",
        "The logistic regression (LR) classifier gave good results with pre-recorded data, however when it came to the real-time implementation, the LR classifier did not perform as well as the simple classifier. After spending some time attempting to fix this error, we decided that the final product would have the simple classifier as we could not find a solution to this problem. We think this may be an issue of integration with the coding, as there may be some difference between the storage of the real-time window data and the pre-recorded training data in wav files, but we were unable to precisely identify this in the time allocated. \n",
        "\n",
        "## Improvements and Future Work \n",
        "\n",
        "Unlike regression, the simple classifier is not robust to blinks. Using the LR classifier and the simple rule based classifier in conjunction would allow for a much more robust and accurate classification. \n",
        "\n",
        "It was also found that the filtered eye movement data was less accurate than the unfiltered data. This was likel the filters were anchored too early based on not enough data. To improve this, we could take a more holistic approach to filtering, experimenting quantitatively with the accuracy of the classifiers after we had developed them, independently varying the frequency range of the filters. \n",
        "\n",
        "Finally, to create a better classifier for the vocal input, we could try measuring the signature waveform of the word, and generating statistics on this such as the Fourier transform to better identify the word. This would also restrict the game to just using the word “shoot” to trigger the laser, rather than just any noise above a certain threshold volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyVCMFGCwZTu"
      },
      "source": [
        "## Future work \n",
        "This solution can be implemented into consoles and computers as a means of access and control, especially improving the lives of those living with a physical disability as it can increase technological convenience and add to their quality of life by enabling more control and accessibility over technology. Further future developments will include increasing the number of bodily inputs accepted to harness greater remote control capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpzATHfsR9Ek"
      },
      "source": [
        "# Conclusion \n",
        "\n",
        "The project successfully built a game with eye movement and voice input using a simple classifier and amplitude detector. Improvements could be made by using the regression classifier for differentiating blinks with the simple classifier for classifying eye movements. Future applications include a headgear embedded with the brainbox like other VR headsets to play games. Moreover, the integration into home computers for those who can’t use a mouse or keyboard.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKJAmV5cU0yH"
      },
      "source": [
        "word count: 2993"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jADMb2LoROkP"
      },
      "source": [
        "# Student Contribution  \n",
        "\n",
        "**Josh** - Helped tune the game parameters to improve playability, was a subject of data collection.\n",
        "\n",
        "**Dylan** - Produced majority of the data-related code sections for the final game. Produced code for figure 2 and figure 3. Report Sections: Method, Discussion, Results.\n",
        "\n",
        "**Leo** - Ideated the space invaders game, assisting in the integration of the game microphone and brainbox input, and contributed in the creation of the presentation and writing of the report (Executive summary, aims and methods & report editing). Wrote various functions for wave transformations and continually tested and verified the performance of our project by attending lab sessions. \n",
        "\n",
        "**Keegan** - Contributed to physics understanding with model development, data collection and integration of the separate input, classifier and game programs. Introduced the audio input to the project and report, and worked to combine the inputs and processing in the code.\n",
        "\n",
        "**Olga** -  Majority of work was in data collection and data pre-processing, classifer work (esp. regression) and the entire feature selection section; report sections: Method+Aim and Background, Evaluation Techniques (produced evaluation plots, confusion matrices and errors), aims (with Keegan), final formatting and tidying up. \n",
        "\n",
        "**Stephen** - Contributed to the physics perspective of the project such as with the model development through the development of filter’s within the game. Worked on the report by contribution to the physics understanding and views of the project and finally with the conclusion. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sodB9CxQs_9A"
      },
      "source": [
        "# References \n",
        "\n",
        "- Bronstein, L. R. (2003). A model for interdisciplinary collaboration. Social work, 48(3), 297-306.\n",
        "\n",
        "- EnhanceDataScience (2017). “Machine Learning Explained: Regularization”. Available at https://www.r-bloggers.com/2017/07/machine-learning-explained-regularization/ \n",
        "\n",
        "- Kelly, C. (2021). “Gaming: The next super platform”. Accenture Software and Platforms Insights. Available at https://www.accenture.com/\n",
        "\n",
        "- Shapiro, E. J., & Dempsey, C. J. (2008). Conflict resolution in team teaching: A case study in interdisciplinary teaching. College teaching, 56(3), 157-162.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkWElDhZTO7O"
      },
      "source": [
        "# Appendices\n",
        "\n",
        "Below is the required imports, globals, and functions to run the following appendices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ3Btb4jbgl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "efa5b245-6442-46bd-9c93-f51f9ae8874c"
      },
      "source": [
        "################################\n",
        "# INSTALL ALL REQUIRED MODULES #\n",
        "################################\n",
        "\n",
        "! python3 -m pip install -r requirements.txt\n",
        "\n",
        "####################\n",
        "# RELEVANT IMPORTS #\n",
        "####################\n",
        "\n",
        "import numpy as np\n",
        "import os, time, sys\n",
        "from scipy.io import wavfile\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import tsfeatures as tf\n",
        "import pandas as pd\n",
        "from cache_decorator import Cache\n",
        "import pickle\n",
        "import enchant\n",
        "from Fourier import if_amplitude_over\n",
        "\n",
        "###########\n",
        "# GLOBALS #\n",
        "###########\n",
        "\n",
        "statistics = {\"flat_spots\" : tf.flat_spots,\n",
        "              \"crossing_points\" : tf.crossing_points,\n",
        "              \"acf_features\" : tf.acf_features,\n",
        "              \"mean\" : np.mean,\n",
        "              \"stdev\": np.std}\n",
        "stat_functions = list(statistics.values())\n",
        "\n",
        "\n",
        "#######################\n",
        "# NECESSARY FUNCTIONS #\n",
        "#######################\n",
        "\n",
        "def find_shortest_distance(a,b):\n",
        "    smallest_dist = None\n",
        "    for i in a:\n",
        "        for j in b:\n",
        "            dist = abs(i - j)\n",
        "            if smallest_dist == None or dist < smallest_dist[0]:\n",
        "                smallest_dist = [dist, i, j]\n",
        "    return (smallest_dist[1], smallest_dist[2])\n",
        "\n",
        "def simple_classifier(data):\n",
        "    pos_peaks = np.where(data == np.amax(data))\n",
        "    neg_peaks = np.where(data == np.amin(data))\n",
        "    pos_peak, neg_peak = find_shortest_distance(pos_peaks[0], neg_peaks[0])\n",
        "    \n",
        "    if pos_peak < neg_peak:\n",
        "        return 0\n",
        "    elif pos_peak > neg_peak:\n",
        "        return 1\n",
        "\n",
        "    return -1\n",
        "\n",
        "def read_wave(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"FILE NOT FOUND: {path}\")\n",
        "        exit()\n",
        "    else:\n",
        "        samplerate, raw_data = wavfile.read(path)\n",
        "        time = np.array(range(0,len(raw_data)))/samplerate\n",
        "        wave = { 'y' : raw_data, 'time' : time, 'samplerate' : samplerate }\n",
        "        return wave\n",
        "\n",
        "def get_actual_labels(path, classifier):\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"ERROR: PATH NOT VALID\")\n",
        "        return None\n",
        "    for root, dirs, files in os.walk(path, topdown=False):\n",
        "        # Iterating through the directory containing training data\n",
        "        for name in files:\n",
        "            if classifier == \"simple\":\n",
        "                if name.endswith(\"S.wav\"):\n",
        "                    wave_file = path + \"/\" + name\n",
        "                    name_lst = wave_file.split(\"_\")\n",
        "                    label = name_lst[len(name_lst)-1]\n",
        "                    \n",
        "                    label = label.strip(\"-S.wav\")\n",
        "                    if (label ==\"R\"):\n",
        "                        label = \"1\"\n",
        "                    else:\n",
        "                        label = \"0\"\n",
        "\n",
        "                    labels.append(label)\n",
        "            else:\n",
        "                wave_file = path + \"/\" + name\n",
        "                name_lst = wave_file.split(\"_\")\n",
        "                label = name_lst[len(name_lst)-1]\n",
        "                \n",
        "                label = label.strip(\".wav\")\n",
        "                if (label ==\"B\"):\n",
        "                    label = \"2\"\n",
        "                elif (label == \"R-S\"):\n",
        "                    label = \"1\"\n",
        "                else:\n",
        "                    label = \"0\"\n",
        "\n",
        "                labels.append(label)\n",
        "\n",
        "    return labels\n",
        "\n",
        "def logistic_read_training_data(path, balance_data = False):\n",
        "    \"\"\"\n",
        "    Reads in the training data .wav files from the specified local directory,\n",
        "    generates statistics on each wave, and outputs the dataset.\n",
        "\n",
        "    @param path     : path to local directory containing training data\n",
        "    @type path      : str\n",
        "    @return dataset : dataset like { waveId : [0, ...], stat1 : [s11, s12, ...], stat2 : [s21, s22, ...], ... }\n",
        "    @rtype          : pandas DataFrame\n",
        "    \"\"\"\n",
        "    data = {}\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"ERROR: PATH NOT VALID\")\n",
        "        return None\n",
        "    \n",
        "    for root, dirs, files in os.walk(path, topdown=False):\n",
        "        # Iterating through the directory containing training data\n",
        "        for name in files:\n",
        "            #print(f\"READING {name}\")\n",
        "            if name.endswith(\".wav\"):\n",
        "                wave_file = path + \"/\" + name\n",
        "                # read the wave file\n",
        "                wave = read_wave(wave_file)\n",
        "                ###### extract label from the filename ##########\n",
        "                name_lst = wave_file.split(\"_\")\n",
        "                label = name_lst[len(name_lst)-1]\n",
        "                if (label == \"B.wav\"):\n",
        "                    label = \"2\" # blink\n",
        "\n",
        "                else:\n",
        "                    label = label.strip(\"-S.wav\")\n",
        "                    if (label ==\"R\"):\n",
        "                        label = \"1\"\n",
        "                    else:\n",
        "                        label = \"0\"\n",
        "                labels.append(label)\n",
        "                colnames, wave_stats = generate_statistics(wave)\n",
        "\n",
        "                # Creating a dictionary in preparation for transformation to a dataframe\n",
        "                for i, col in enumerate(colnames):\n",
        "                    if not data.get(col):\n",
        "                        # For the first iteration of the loop\n",
        "                        data[col] = [wave_stats[i]]\n",
        "                    else:\n",
        "                        data[col].append(wave_stats[i])\n",
        "    data[\"labels\"] = labels\n",
        "    data = pd.DataFrame(data)\n",
        "    if (balance_data):\n",
        "        data = balance_dataset(data)\n",
        "    return data\n",
        "\n",
        "def balance_dataset(data):\n",
        "    len_r = len(data[data[\"labels\"]==\"1\"])\n",
        "    len_l = len(data[data[\"labels\"]==\"0\"])\n",
        "\n",
        "    smallest = len_l if len_r > len_l else len_r\n",
        "\n",
        "    data_right = data[data[\"labels\"]==\"1\"].sample(smallest, random_state=0)\n",
        "    data_left = data[data[\"labels\"]==\"0\"].sample(smallest, random_state=0)\n",
        "    dat = pd.concat([data_right, data_left])\n",
        "    return dat\n",
        "\n",
        "def simple_prediction(path):\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"ERROR: PATH NOT VALID\")\n",
        "        return None\n",
        "    \n",
        "    for root, dirs, files in os.walk(path, topdown=False):\n",
        "        # Iterating through the directory containing training data\n",
        "        for name in files:\n",
        "            if name.endswith(\"S.wav\"):\n",
        "                \n",
        "                wave_file = path + \"/\" + name\n",
        "                wave = read_wave(wave_file)\n",
        "                label = simple_classifier(wave['y'])\n",
        "                labels.append(str(label))\n",
        "    return labels\n",
        "\n",
        "def logistic_prediction(path, classifier, scaler):\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"ERROR: PATH NOT VALID\")\n",
        "        return None\n",
        "    \n",
        "    for root, dirs, files in os.walk(path, topdown=False):\n",
        "        # Iterating through the directory containing training data\n",
        "        for name in files:\n",
        "            wave_file = path + \"/\" + name\n",
        "            #print(f\"Predicting {wave_file}...\")\n",
        "            wave = read_wave(wave_file)\n",
        "            label = predict(wave, classifier, scaler)\n",
        "            #print(f\"Predicted: {label}\")\n",
        "            labels.append(str(label[0]))\n",
        "                \n",
        "    return labels\n",
        "\n",
        "\n",
        "def build_classifier(training_path, wave_type, classifier = \"LR\", show_acc = False):\n",
        "    \"\"\"\n",
        "    Builds the specific classifier - default is Logistic Regression - and trains it on the training data.\n",
        "\n",
        "    @param training_path : local directory containining training data, i.e., .wav files and .txt files\n",
        "    @type training_path  : str\n",
        "    @param classifier    : which classifier to use\n",
        "    @type classifier     : str\n",
        "    @param show_acc      : flag used to show classifier accuracy\n",
        "    @type show_acc       : boolean\n",
        "    @return classifier   : linear regression classifier\n",
        "    @rtype               : sklearn.linear_model type object\n",
        "    \"\"\"\n",
        "    dataset = logistic_read_training_data(training_path)\n",
        "\n",
        "    dataset = dataset[['flat_spots', 'crossing_points', 'diff2_acf10', 'stdev', 'labels']]\n",
        "\n",
        "    # Take necessary rows and split labels into new dataset, y\n",
        "    X = dataset.drop([\"labels\"], axis=1).values\n",
        "    y = list(dataset[\"labels\"])\n",
        "    # Scale the data\n",
        "    sc_X = StandardScaler()\n",
        "    X = sc_X.fit_transform(X)\n",
        "    # Divide into training (75%) and testing (25%) sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "    ######## binary classifier, l2 reg ##########\n",
        "    classifier = LogisticRegression(multi_class= \"multinomial\", solver='saga', penalty = 'l2')\n",
        "    classifier.fit(X, y) \n",
        "    if show_acc:\n",
        "        determine_accuracy(classifier, X_test, y_test)\n",
        "        plot_accuracy(classifier, X, y)\n",
        "\n",
        "    # write classifier\n",
        "    model_filename = f'model_{wave_type}.sav'\n",
        "    pickle.dump(classifier, open(model_filename, 'wb'))\n",
        "    \n",
        "    # write scaler\n",
        "    scaler_filename = f'scaler_{wave_type}.sav'\n",
        "    pickle.dump(sc_X, open(scaler_filename, 'wb'))\n",
        "\n",
        "    return classifier, sc_X\n",
        "\n",
        "def determine_accuracy(model, X, y):\n",
        "    \"\"\"\n",
        "    Generates a confusion matrix for the input predicted and target labels.\n",
        "\n",
        "    @param model : Fitted logisitic regression model\n",
        "    @type model  : sklearn.linear_model type object\n",
        "    @param X     : All data (minus labels)\n",
        "    @type X      : numpy array\n",
        "    @param y     : Corresponding labels\n",
        "    @type y      : numpy array\n",
        "    \"\"\"\n",
        "    y_true = list(y)\n",
        "    y_pred = model.predict(X)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def plot_accuracy(model, X, y):\n",
        "    \"\"\"\n",
        "    Runs repeated CV on the model and returns the mean and sd of the accuracy to 3 decimal places.\n",
        "\n",
        "    @param model : Fitted logisitic regression model\n",
        "    @type model  : sklearn.linear_model type object\n",
        "    @param X     : All data (minus labels)\n",
        "    @type X      : numpy array\n",
        "    @param y     : Corresponding labels\n",
        "    @type y      : numpy array\n",
        "    \"\"\"\n",
        "\n",
        "    # define the model evaluation procedure\n",
        "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\n",
        "    # evaluate the model and collect the scores\n",
        "    n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "    # report the model performance\n",
        "    plt.boxplot(list(n_scores))\n",
        "    plt.title(\"4-fold CV Accuracy (10 repeats)\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.xlabel(\"\")\n",
        "    plt.show()\n",
        "    # print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
        "\n",
        "def generate_statistics(wave):\n",
        "    \"\"\"\n",
        "    Generates the globally defined statistics* about a given wave (* see variable 'statistics')\n",
        "\n",
        "    @param wave        : wave object\n",
        "    @type wave         : dictionary\n",
        "    @return colnames   : names of generated statistics (note: has wave_stats ordering)\n",
        "    @rtype colnames    : list\n",
        "    @return wave_stats : generated statistics (note: has colnames ordering)\n",
        "    @rtype wave_stats  : list\n",
        "    \"\"\"\n",
        "    stats = {}\n",
        "    Y = wave['y']\n",
        "    i=0\n",
        "    for fun in stat_functions:\n",
        "        dic = fun(Y)\n",
        "        #print(dic)\n",
        "        try:\n",
        "            for k,v in dic.items():\n",
        "                stats[k] = v\n",
        "        except:\n",
        "            if (i == 0):\n",
        "                stats[\"mean\"] = dic\n",
        "                i+=1\n",
        "            else:\n",
        "                stats[\"stdev\"] = dic\n",
        "                \n",
        "    colnames = list(stats.keys())\n",
        "    wave_stats = list(stats.values())\n",
        "    return colnames, wave_stats\n",
        "\n",
        "def predict(wave, classifier, standard_scaler):\n",
        "    colnames, wave_stats = generate_statistics(wave)\n",
        "    wave_stats_reshape = np.reshape(wave_stats, (1,-1))\n",
        "    # create a dataframe\n",
        "    wave_stats_dataframe = pd.DataFrame(wave_stats_reshape, columns = colnames)\n",
        "    # select specific stats\n",
        "    wave_stats = wave_stats_dataframe[['flat_spots', 'crossing_points', 'diff2_acf10', 'stdev']]\n",
        "    # just the values in an array\n",
        "    wave_stats = np.array(wave_stats.values)\n",
        "    # normalise\n",
        "    wave_stats = standard_scaler.transform(wave_stats)\n",
        "    # predict.\n",
        "    label = classifier.predict(wave_stats)\n",
        "    return label   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f1c57e4dab19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtsfeatures\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcache_decorator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tsfeatures'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdg5helz7idh"
      },
      "source": [
        "## Appendix A\n",
        "_Code to produce Figure 1_\n",
        "\n",
        "> Note: This may take some time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1eODlpybgl7"
      },
      "source": [
        "wave_types = [\"waves\", \"filtered\"]\n",
        "classifiers = [\"simple\", \"LR\"]\n",
        "data_path = \"training_data/spiker_waves\"\n",
        "build_classifier(data_path, wave_type=\"waves\", show_acc=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxwnh9Sjbgl7"
      },
      "source": [
        "## Appendix B\n",
        "_Code to produce Figure 2_\n",
        "\n",
        "> The data within latencies.csv was pre-collected as it requires connection to a spikerbox."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nRqE-Ihbgl7",
        "outputId": "22456b49-1230-41ba-96b5-8ac8c9b06084"
      },
      "source": [
        "with open(\"./latencies.csv\") as f:\n",
        "    latencies = [round(float(x.split(\",\")[0])*1000, 5) for x in f.readlines()[1:]]\n",
        "time = [x/10 for x in range(len(latencies))]\n",
        "\n",
        "line = np.mean(latencies)+(3*np.std(latencies))\n",
        "\n",
        "plt.plot(time, latencies, color = \"black\")\n",
        "plt.axis([0,62,0,45])\n",
        "plt.hlines(y=line, xmin=0, xmax=62, color = \"Red\")\n",
        "plt.title(\"Ship Movement Latency over 1 Minute\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Latency (ms)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BFG90LFbgl8",
        "outputId": "4149066c-bf97-4160-eb35-6937a7b32527"
      },
      "source": [
        "np.std(latencies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.234722229944538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o9E3CR5bgl8"
      },
      "source": [
        "## Appendix C\n",
        "_Code to produce Figure 3_\n",
        "\n",
        "> Note: This may take a very long time. Double click **here** to see the expected output before you see a graph...\n",
        "\n",
        "<!-- \n",
        "Trying wave 1 with window_size = 0.5 seconds and overlap_factor=0.5\n",
        "Trying wave 1 with window_size = 0.5 seconds and overlap_factor=1\n",
        "Trying wave 2 with window_size = 0.5 seconds and overlap_factor=0.5\n",
        "Trying wave 2 with window_size = 0.5 seconds and overlap_factor=1\n",
        "Trying wave 3 with window_size = 0.5 seconds and overlap_factor=0.5\n",
        "Trying wave 3 with window_size = 0.5 seconds and overlap_factor=1\n",
        "Trying wave 1 with window_size = 1 seconds and overlap_factor=0.5\n",
        "Trying wave 1 with window_size = 1 seconds and overlap_factor=1\n",
        "Trying wave 2 with window_size = 1 seconds and overlap_factor=0.5\n",
        "Trying wave 2 with window_size = 1 seconds and overlap_factor=1\n",
        "Trying wave 3 with window_size = 1 seconds and overlap_factor=0.5\n",
        "Trying wave 3 with window_size = 1 seconds and overlap_factor=1\n",
        "Trying wave 1 with window_size = 1.5 seconds and overlap_factor=0.5\n",
        "Trying wave 1 with window_size = 1.5 seconds and overlap_factor=1\n",
        "Trying wave 2 with window_size = 1.5 seconds and overlap_factor=0.5\n",
        "Trying wave 2 with window_size = 1.5 seconds and overlap_factor=1\n",
        "Trying wave 3 with window_size = 1.5 seconds and overlap_factor=0.5\n",
        "Trying wave 3 with window_size = 1.5 seconds and overlap_factor=1\n",
        "Trying wave 1 with window_size = 2 seconds and overlap_factor=0.5\n",
        "Trying wave 1 with window_size = 2 seconds and overlap_factor=1\n",
        "Trying wave 2 with window_size = 2 seconds and overlap_factor=0.5\n",
        "Trying wave 2 with window_size = 2 seconds and overlap_factor=1\n",
        "Trying wave 3 with window_size = 2 seconds and overlap_factor=0.5\n",
        "Trying wave 3 with window_size = 2 seconds and overlap_factor=1\n",
        "Trying wave 1 with window_size = 2.5 seconds and overlap_factor=0.5\n",
        "Trying wave 1 with window_size = 2.5 seconds and overlap_factor=1\n",
        "Trying wave 2 with window_size = 2.5 seconds and overlap_factor=0.5\n",
        "Trying wave 2 with window_size = 2.5 seconds and overlap_factor=1\n",
        "Trying wave 3 with window_size = 2.5 seconds and overlap_factor=0.5\n",
        "Trying wave 3 with window_size = 2.5 seconds and overlap_factor=1 \n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRapsghvbgl8"
      },
      "source": [
        "# Read in trained logistic regression model and associated scaler \n",
        "model_filename = \"model_waves.sav\"\n",
        "scaler_filename = \"scaler_waves.sav\"\n",
        "\n",
        "if os.path.exists(model_filename) and os.path.exists(scaler_filename):                      \n",
        "    classifier = pickle.load(open(model_filename, 'rb'))\n",
        "    scaler = pickle.load(open(scaler_filename, 'rb'))\n",
        "else:\n",
        "    print(\"ERROR: Cannot find model and scalar.\")\n",
        "\n",
        "statistics = {\"flat_spots\" : tf.flat_spots,\n",
        "              \"crossing_points\" : tf.crossing_points,\n",
        "              \"acf_features\" : tf.acf_features,\n",
        "              \"mean\" : np.mean,\n",
        "              \"stdev\": np.std}\n",
        "\n",
        "stat_functions = list(statistics.values())    \n",
        "\n",
        "def generate_statistics(wave):\n",
        "    stats = {}\n",
        "    Y = wave\n",
        "    i=0\n",
        "    for fun in stat_functions:\n",
        "        dic = fun(Y)\n",
        "        try:\n",
        "            for k,v in dic.items():\n",
        "                stats[k] = v\n",
        "        except:\n",
        "            if (i == 0):\n",
        "                stats[\"mean\"] = dic\n",
        "                i+=1\n",
        "            else:\n",
        "                stats[\"stdev\"] = dic\n",
        "                \n",
        "    colnames = list(stats.keys())\n",
        "    wave_stats = list(stats.values())\n",
        "    return colnames, wave_stats\n",
        "    \n",
        "def predict(wave, classifier, standard_scaler):\n",
        "    colnames, wave_stats = generate_statistics(wave)\n",
        "    # get rid of nan values\n",
        "    #wave_stats[np.isnan(wave_stats)] = 0\n",
        "    wave_stats_reshape = np.reshape(wave_stats, (1,-1))\n",
        "    # create a dataframe\n",
        "    wave_stats_dataframe = pd.DataFrame(wave_stats_reshape, columns = colnames)\n",
        "    # select specific stats\n",
        "    wave_stats = wave_stats_dataframe[['flat_spots', 'crossing_points', 'diff2_acf10', 'stdev']]\n",
        "    # just the values in an array\n",
        "    wave_stats = np.array(wave_stats.values)\n",
        "    # normalise\n",
        "\n",
        "    wave_stats = standard_scaler.transform(wave_stats)\n",
        "    # predict.\n",
        "    label = int(classifier.predict(wave_stats)[0])\n",
        "    return label    \n",
        "    \n",
        "    \n",
        "def find_shortest_distance(a,b):\n",
        "    smallest_dist = None\n",
        "    for i in a[0]:\n",
        "        for j in b[0]:\n",
        "            dist = abs(i - j)\n",
        "            if smallest_dist == None or dist < smallest_dist[0]:\n",
        "                smallest_dist = (dist, i, j)\n",
        "    return smallest_dist[1], smallest_dist[2]\n",
        "\n",
        "def simple_classify(data):\n",
        "    pos_peaks = np.where(data == np.amax(data))\n",
        "    neg_peaks = np.where(data == np.amin(data))\n",
        "    pos_peak, neg_peak = find_shortest_distance(pos_peaks, neg_peaks)\n",
        "    if pos_peak < neg_peak:\n",
        "        return \"L\"\n",
        "    elif pos_peak >= neg_peak:\n",
        "        return \"R\"\n",
        "\n",
        "live_recordings_path = \"training_data/streamed/\"\n",
        "\n",
        "def run_classifier(wave_filename, window_size, true_labels, overlap_factor):\n",
        "    try:\n",
        "        wave_path = live_recordings_path + wave_filename\n",
        "        samplerate, raw_wave = wavfile.read(wave_path)\n",
        "        actual_samplerate = int(samplerate/2) # this is due to incorrect writing of the header at recording time, it is actually 10000 not 20000, making the total wave time 1 minute and not 30 seconds.\n",
        "        increment = int(actual_samplerate * window_size)\n",
        "        predicted = []\n",
        "        start_interval = 0\n",
        "        end_interval = increment\n",
        "        while True:\n",
        "\n",
        "            if start_interval >= len(raw_wave) or end_interval > len(raw_wave):\n",
        "                break         \n",
        "            \n",
        "            # only look at desired window\n",
        "            window = raw_wave[start_interval:end_interval]\n",
        "            \n",
        "            # UNCOMMENT TO SEE WINDOWS\n",
        "            # plt.plot(window)\n",
        "            # plt.axis([0,10000,400,650])\n",
        "            # plt.show()\n",
        "\n",
        "            # filter out noise using logistic regression\n",
        "            movement_bool = predict(window, classifier, scaler)\n",
        "            if movement_bool != 2:\n",
        "                # add to predicted labels\n",
        "                predicted_label = simple_classify(window)\n",
        "                predicted.append(predicted_label)\n",
        "            \n",
        "            # slide window\n",
        "            start_interval += int(increment * overlap_factor)\n",
        "            end_interval += int(increment * overlap_factor)\n",
        "            \n",
        "        # print(f\"{predicted=}\\n{true_labels=}\")\n",
        "        correctly_predicted = len(true_labels) - enchant.utils.levenshtein(\"\".join(predicted), \"\".join(true_labels))\n",
        "        acc = (correctly_predicted / len(true_labels)) * 100\n",
        "        return acc\n",
        "        \n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"ERROR: Cannot find {wave_filename}. Please check that {wave_filename} is stored in {live_recordings_path}.\")\n",
        "        \n",
        "waves = [\n",
        "    \"spiker_recording_2021-05-25_15.00.54_streamed.wav\", \n",
        "    \"spiker_recording_2021-05-25_15.03.13_streamed.wav\", \n",
        "    \"spiker_recording_2021-05-25_15.17.56_streamed.wav\"\n",
        "    ]\n",
        "\n",
        "wave_true_labels = [\n",
        "    [\"R\", \"L\", \"R\", \"R\", \"R\", \"L\", \"R\", \"R\", \"L\", \"R\", \"R\", \"L\", \"R\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\", \"R\", \"R\", \"L\", \"L\", \"R\", \"R\", \"L\", \"L\", \"R\", \"L\", \"L\", \"R\", \"R\", \"R\", \"L\", \"L\", \"R\", \"L\", \"L\", \"L\"],\n",
        "    [\"L\", \"L\", \"R\", \"R\", \"R\", \"L\", \"L\", \"R\", \"L\", \"R\", \"R\", \"L\", \"R\", \"L\", \"R\", \"R\", \"L\", \"L\", \"R\", \"R\", \"L\", \"R\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\"],\n",
        "    [\"L\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\", \"L\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\", \"R\", \"L\", \"L\", \"L\", \"R\"]\n",
        "]\n",
        "\n",
        "greatest_acc = 0\n",
        "optimal_window_size = 1\n",
        "window_accuracies_half_overlap = []\n",
        "window_accuracies_no_overlap = []\n",
        "window_sizes = [0.5, 1, 1.5, 2, 2.5]\n",
        "overlap_factors = [0.5, 1]\n",
        "most_accurate_method = None\n",
        "\n",
        "for indpnt_time_var in window_sizes:\n",
        "    wave_accuracies_half_overlap = []\n",
        "    wave_accuracies_no_overlap = []\n",
        "    for i, wave_filename in enumerate(waves):\n",
        "        for overlap_factor in overlap_factors:\n",
        "            \n",
        "            print(f\"Trying wave {i+1} with window_size = {indpnt_time_var} seconds and {overlap_factor=}\")\n",
        "\n",
        "            acc = run_classifier(wave_filename, window_size = indpnt_time_var, true_labels = wave_true_labels[i], overlap_factor=overlap_factor)\n",
        "\n",
        "            if acc == -1:\n",
        "                # In case of file not found error\n",
        "                sys.exit(-1)\n",
        "\n",
        "            if overlap_factor == 0.5:\n",
        "                wave_accuracies_half_overlap.append(acc) \n",
        "            else:\n",
        "                wave_accuracies_no_overlap.append(acc)\n",
        "            \n",
        "        # Half overlap\n",
        "        mean_wave_acc_half_overlap = np.mean(wave_accuracies_half_overlap)\n",
        "        window_accuracies_half_overlap.append(mean_wave_acc_half_overlap)\n",
        "        \n",
        "        # No overlap\n",
        "        mean_wave_acc_no_overlap = np.mean(wave_accuracies_no_overlap)\n",
        "        window_accuracies_no_overlap.append(mean_wave_acc_no_overlap)\n",
        "    \n",
        "    if mean_wave_acc_half_overlap >= greatest_acc:\n",
        "        optimal_window_size = indpnt_time_var\n",
        "        greatest_acc = mean_wave_acc\n",
        "        most_accurate_method = \"Half Overlap\"\n",
        "    if mean_wave_acc_no_overlap >= greatest_acc:\n",
        "        optimal_window_size = indpnt_time_var\n",
        "        greatest_acc = mean_wave_acc\n",
        "        most_accurate_method = \"No Overlap\"\n",
        "\n",
        "overlap = [\"Half\", \"None\"]\n",
        "window_size_05 = [window_accuracies_half_overlap[0], window_accuracies_no_overlap[0]]\n",
        "window_size_1 = [window_accuracies_half_overlap[1], window_accuracies_no_overlap[1]]\n",
        "window_size_15 = [window_accuracies_half_overlap[2], window_accuracies_no_overlap[2]]\n",
        "window_size_2 = [window_accuracies_half_overlap[3], window_accuracies_no_overlap[3]]\n",
        "window_size_25 = [window_accuracies_half_overlap[4], window_accuracies_no_overlap[4]]\n",
        "\n",
        "X_axis = np.arange(len(overlap))\n",
        "\n",
        "plt.bar(X_axis - 0.2, window_size_05, 0.1, label = '0.5s')\n",
        "plt.bar(X_axis - 0.1, window_size_1, 0.1, label = '1s')\n",
        "plt.bar(X_axis, window_size_15, 0.1, label = '1.5s')\n",
        "plt.bar(X_axis + 0.1, window_size_2, 0.1, label = '2s')\n",
        "plt.bar(X_axis + 0.2, window_size_25, 0.1, label = '2.5s')\n",
        "  \n",
        "plt.xticks(X_axis, overlap)\n",
        "plt.xlabel(\"Overlap Factor\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Combined classifiers accuracies across varying window sizes and overlap factors\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TdBl-99bgl-"
      },
      "source": [
        "## Appendix D\n",
        "_Code to produce accuracy standard deviation across the 3 1-minute long waves using in [Qualitative Evaluation](#Qualitative-Evaluation)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YklWR1xBbgl-",
        "outputId": "d35f10a6-9004-44f6-d8b0-507b2e683fe5"
      },
      "source": [
        "# Below are the results used to plot Figure 3 (saved as a png)\n",
        "window_accuracies_half_overlap=[-179.4871794871795, -206.4102564102564, -238.94017094017093, -51.28205128205128, -78.97435897435898, -104.64957264957265, 7.6923076923076925, -14.487179487179485, -33.65811965811966, 48.717948717948715, 32.69230769230769, 20.461538461538463, 56.41025641025641, 48.205128205128204, 41.47008547008547]\n",
        "window_accuracies_no_overlap=[2.564102564102564, -10.384615384615383, -26.923076923076923, 64.1025641025641, 53.717948717948715, 46.47863247863248, 74.35897435897436, 70.51282051282051, 67.00854700854701, 69.23076923076923, 69.61538461538461, 71.74358974358974, 56.41025641025641, 58.205128205128204, 62.8034188034188]\n",
        "\n",
        "print(\"Wave 1 SD (Half Overlap): \", round(np.std(window_accuracies_half_overlap[::3]), 2),\"%\")\n",
        "print(\"Wave 2 SD (Half Overlap): \", round(np.std(window_accuracies_half_overlap[1::3]), 2),\"%\")\n",
        "print(\"Wave 3 SD (Half Overlap): \", round(np.std(window_accuracies_half_overlap[2::3]), 2),\"%\")\n",
        "\n",
        "print(\"Wave 1 SD (No Overlap): \", round(np.std(window_accuracies_no_overlap[::3]), 2),\"%\")\n",
        "print(\"Wave 2 SD (No Overlap): \", round(np.std(window_accuracies_no_overlap[1::3]), 2),\"%\")\n",
        "print(\"Wave 3 SD (No Overlap): \", round(np.std(window_accuracies_no_overlap[2::3]), 2),\"%\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wave 1 SD (Half Overlap):  86.81 %\n",
            "Wave 2 SD (Half Overlap):  92.58 %\n",
            "Wave 3 SD (Half Overlap):  101.42 %\n",
            "Wave 1 SD (No Overlap):  26.07 %\n",
            "Wave 2 SD (No Overlap):  30.06 %\n",
            "Wave 3 SD (No Overlap):  36.57 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSX2X_7dbgl_"
      },
      "source": [
        "## Appendix E\n",
        "_Code to produce simple rule based classifier confusion matrix_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3dVuSRUbgl_",
        "outputId": "5fad521d-9c0e-4050-8f2d-3e73c42dc237"
      },
      "source": [
        "def find_shortest_distance(a,b):\n",
        "    smallest_dist = None\n",
        "    for i in a:\n",
        "        for j in b:\n",
        "            dist = abs(i - j)\n",
        "            if smallest_dist == None or dist < smallest_dist[0]:\n",
        "                smallest_dist = [dist, i, j]\n",
        "    return (smallest_dist[1], smallest_dist[2])\n",
        "\n",
        "def simple_classifier(data):\n",
        "    pos_peaks = np.where(data == np.amax(data))\n",
        "    neg_peaks = np.where(data == np.amin(data))\n",
        "    pos_peak, neg_peak = find_shortest_distance(pos_peaks[0], neg_peaks[0])\n",
        "    \n",
        "    if pos_peak < neg_peak:\n",
        "        return 0\n",
        "    elif pos_peak > neg_peak:\n",
        "        return 1\n",
        "\n",
        "    return -1\n",
        "\n",
        "def read_wave(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"FILE NOT FOUND: {path}\")\n",
        "        exit()\n",
        "    else:\n",
        "        samplerate, raw_data = wavfile.read(path)\n",
        "        time = np.array(range(0,len(raw_data)))/samplerate\n",
        "        wave = { 'y' : raw_data, 'time' : time, 'samplerate' : samplerate }\n",
        "        return wave\n",
        "\n",
        "def get_actual_labels(path, classifier):\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"ERROR: PATH NOT VALID\")\n",
        "        return None\n",
        "    for root, dirs, files in os.walk(path, topdown=False):\n",
        "        # Iterating through the directory containing training data\n",
        "        for name in files:\n",
        "            if classifier == \"simple\":\n",
        "                if name.endswith(\"S.wav\"):\n",
        "                    wave_file = path + \"/\" + name\n",
        "                    name_lst = wave_file.split(\"_\")\n",
        "                    label = name_lst[len(name_lst)-1]\n",
        "                    \n",
        "                    label = label.strip(\"-S.wav\")\n",
        "                    if (label ==\"R\"):\n",
        "                        label = \"1\"\n",
        "                    else:\n",
        "                        label = \"0\"\n",
        "\n",
        "                    labels.append(label)\n",
        "            else:\n",
        "                wave_file = path + \"/\" + name\n",
        "                name_lst = wave_file.split(\"_\")\n",
        "                label = name_lst[len(name_lst)-1]\n",
        "                \n",
        "                label = label.strip(\".wav\")\n",
        "                if (label ==\"B\"):\n",
        "                    label = \"2\"\n",
        "                elif (label == \"R-S\"):\n",
        "                    label = \"1\"\n",
        "                else:\n",
        "                    label = \"0\"\n",
        "\n",
        "                labels.append(label)\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def logistic_read_training_data(path, balance_data = False):\n",
        "    \"\"\"\n",
        "    Reads in the training data .wav files from the specified local directory,\n",
        "    generates statistics on each wave, and outputs the dataset.\n",
        "\n",
        "    @param path     : path to local directory containing training data\n",
        "    @type path      : str\n",
        "    @return dataset : dataset like { waveId : [0, ...], stat1 : [s11, s12, ...], stat2 : [s21, s22, ...], ... }\n",
        "    @rtype          : pandas DataFrame\n",
        "    \"\"\"\n",
        "    data = {}\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"ERROR: PATH NOT VALID\")\n",
        "        return None\n",
        "    \n",
        "    for root, dirs, files in os.walk(path, topdown=False):\n",
        "        # Iterating through the directory containing training data\n",
        "        for name in files:\n",
        "            print(f\"READING {name}\")\n",
        "            if name.endswith(\".wav\"):\n",
        "                wave_file = path + \"/\" + name\n",
        "                # read the wave file\n",
        "                wave = read_wave(wave_file)\n",
        "                #print(wave)\n",
        "                # TODO: Either use find_eye_movements function here to get intervals of movement for each training\n",
        "                #       data .wav file OR we can use the txt files (still unsure how to interpret them though)\n",
        "\n",
        "                ###### extract label from the filename ##########\n",
        "                name_lst = wave_file.split(\"_\")\n",
        "                label = name_lst[len(name_lst)-1]\n",
        "                if (label == \"B.wav\"):\n",
        "                    label = \"2\" # blink\n",
        "\n",
        "                else:\n",
        "                    label = label.strip(\"-S.wav\")\n",
        "                    if (label ==\"R\"):\n",
        "                        label = \"1\"\n",
        "                    else:\n",
        "                        label = \"0\"\n",
        "\n",
        "                labels.append(label)\n",
        "                colnames, wave_stats = generate_statistics(wave)\n",
        "\n",
        "                # Creating a dictionary in preparation for transformation to a dataframe\n",
        "                for i, col in enumerate(colnames):\n",
        "                    if not data.get(col):\n",
        "                        # For the first iteration of the loop\n",
        "                        data[col] = [wave_stats[i]]\n",
        "                    else:\n",
        "                        data[col].append(wave_stats[i])\n",
        "\n",
        "    data[\"labels\"] = labels\n",
        "    # print(labels)\n",
        "    ############ remove blinks for now ###############\n",
        "    data = pd.DataFrame(data)\n",
        "    #data = data[data[\"labels\"]!=\"2\"]\n",
        "    # print(data)\n",
        "    if (balance_data):\n",
        "        data = balance_dataset(data)\n",
        "    return data\n",
        "\n",
        "def balance_dataset(data):\n",
        "    len_r = len(data[data[\"labels\"]==\"1\"])\n",
        "    len_l = len(data[data[\"labels\"]==\"0\"])\n",
        "\n",
        "    smallest = len_l if len_r > len_l else len_r\n",
        "\n",
        "    data_right = data[data[\"labels\"]==\"1\"].sample(smallest, random_state=0)\n",
        "    data_left = data[data[\"labels\"]==\"0\"].sample(smallest, random_state=0)\n",
        "    dat = pd.concat([data_right, data_left])\n",
        "    return dat\n",
        "\n",
        "def simple_prediction(path):\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"ERROR: PATH NOT VALID\")\n",
        "        return None\n",
        "    \n",
        "    for root, dirs, files in os.walk(path, topdown=False):\n",
        "        # Iterating through the directory containing training data\n",
        "        for name in files:\n",
        "            if name.endswith(\"S.wav\"):\n",
        "                \n",
        "                wave_file = path + \"/\" + name\n",
        "                wave = read_wave(wave_file)\n",
        "                label = simple_classifier(wave['y'])\n",
        "                labels.append(str(label))\n",
        "                \n",
        "    return labels\n",
        "\n",
        "def logistic_prediction(path, classifier, scaler):\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"ERROR: PATH NOT VALID\")\n",
        "        return None\n",
        "    \n",
        "    for root, dirs, files in os.walk(path, topdown=False):\n",
        "        # Iterating through the directory containing training data\n",
        "        for name in files:\n",
        "            \n",
        "            wave_file = path + \"/\" + name\n",
        "            print(f\"Predicting {wave_file}...\")\n",
        "            wave = read_wave(wave_file)\n",
        "            label = predict(wave, classifier, scaler)\n",
        "            print(f\"Predicted: {label}\")\n",
        "            labels.append(str(label[0]))\n",
        "                \n",
        "    return labels\n",
        "\n",
        "\n",
        "def build_classifier(training_path, wave_type, classifier = \"LR\", show_acc = False):\n",
        "    # REFERENCE: https://in.springboard.com/blog/logistic-regression-explained/\n",
        "    \"\"\"\n",
        "    Builds the specific classifier - default is Logistic Regression - and trains it on the training data.\n",
        "\n",
        "    @param training_path : local directory containining training data, i.e., .wav files and .txt files\n",
        "    @type training_path  : str\n",
        "    @param classifier    : which classifier to use\n",
        "    @type classifier     : str\n",
        "    @param show_acc      : flag used to show classifier accuracy\n",
        "    @type show_acc       : boolean\n",
        "    @return classifier   : linear regression classifier\n",
        "    @rtype               : sklearn.linear_model type object\n",
        "    \"\"\"\n",
        "    dataset = logistic_read_training_data(training_path)\n",
        "\n",
        "    ########## left and right only ################\n",
        "    #dataset = dataset[dataset[\"labels\"]!=\"2\"]\n",
        "\n",
        "    ######## specify the features after running lasso feature selection ##########\n",
        "    #dataset = dataset[['diff2_acf10', 'stdev', 'labels']]\n",
        "    dataset = dataset[['flat_spots', 'crossing_points', 'diff2_acf10', 'stdev', 'labels']]\n",
        "\n",
        "    # Take necessary rows and split labels into new dataset, y\n",
        "    X = dataset.drop([\"labels\"], axis=1).values\n",
        "    y = list(dataset[\"labels\"])\n",
        "    # Divide into training (75%) and testing (25%) sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "    # Scale the data\n",
        "    sc_X = StandardScaler()\n",
        "    X_train = sc_X.fit_transform(X_train)\n",
        "    X_test = sc_X.transform(X_test)\n",
        "\n",
        "    ####### use this to test on the whole dataset #######\n",
        "    #sc_X = StandardScaler()\n",
        "    #X = sc_X.fit_transform(X)\n",
        "\n",
        "    ##### multilinear ######\n",
        "    #classifier = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "\n",
        "    ######## binary classifier, l2 reg ##########\n",
        "    classifier = LogisticRegression(multi_class= \"multinomial\", solver='saga', penalty = 'l2')\n",
        "    #########################\n",
        "    classifier.fit(X, y) #TODO: change this back to X_train, y_train\n",
        "    \n",
        "    if show_acc:\n",
        "        determine_accuracy(classifier, X_test, y_test)\n",
        "        plot_accuracy(classifier, X, y)\n",
        "\n",
        "    # write classifier\n",
        "    model_filename = f'model_{wave_type}.sav'\n",
        "    pickle.dump(classifier, open(model_filename, 'wb'))\n",
        "    \n",
        "    # write scaler\n",
        "    scaler_filename = f'scaler_{wave_type}.sav'\n",
        "    pickle.dump(sc_X, open(scaler_filename, 'wb'))\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # predict the class label\n",
        "    # row = generate_statistics(wave)\n",
        "    # y_hat = model.predict([row])\n",
        "    # OR predict a multinomial probability distribution\n",
        "    # y_hat = model.predict_proba([row])\n",
        "    #classifier.predict(X_test)\n",
        "    return classifier, sc_X\n",
        "\n",
        "def determine_accuracy(model, X, y):\n",
        "    \"\"\"\n",
        "    Runs repeated CV on the model and returns the mean and sd of the accuracy to 3 decimal places.\n",
        "\n",
        "    @param model : Fitted logisitic regression model\n",
        "    @type model  : sklearn.linear_model type object\n",
        "    @param X     : All data (minus labels)\n",
        "    @type X      : numpy array\n",
        "    @param y     : Corresponding labels\n",
        "    @type y      : numpy array\n",
        "    \"\"\"\n",
        "    # make fake dataset (can delete later)\n",
        "    # X, y = make_classification(n_samples=72, n_features=5, n_informative=5, n_redundant=0, n_classes=3, random_state=1)\n",
        "    y_true = list(y)\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    \n",
        "\n",
        "    # define the model evaluation procedure\n",
        "    # cv = RepeatedStratifiedKFold(n_splits=1, n_repeats=3, random_state=1)\n",
        "    # evaluate the model and collect the scores\n",
        "    # n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "    # report the model performance\n",
        "\n",
        "    # print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
        "\n",
        "def plot_accuracy(model, X, y):\n",
        "    \"\"\"\n",
        "    Runs repeated CV on the model and returns the mean and sd of the accuracy to 3 decimal places.\n",
        "\n",
        "    @param model : Fitted logisitic regression model\n",
        "    @type model  : sklearn.linear_model type object\n",
        "    @param X     : All data (minus labels)\n",
        "    @type X      : numpy array\n",
        "    @param y     : Corresponding labels\n",
        "    @type y      : numpy array\n",
        "    \"\"\"\n",
        "\n",
        "    # define the model evaluation procedure\n",
        "    cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=10, random_state=1)\n",
        "    # evaluate the model and collect the scores\n",
        "    n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "    # report the model performance\n",
        "\n",
        "    plt.boxplot(list(n_scores))\n",
        "    plt.title(\"4-fold CV Accuracy (10 repeats)\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.xlabel(\"\")\n",
        "    plt.show()\n",
        "    # print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
        "\n",
        "statistics = {\"flat_spots\" : tf.flat_spots,\n",
        "              \"crossing_points\" : tf.crossing_points,\n",
        "              \"acf_features\" : tf.acf_features,\n",
        "              \"mean\" : np.mean,\n",
        "              \"stdev\": np.std} # olga: see lasso_feature_selection\n",
        "\n",
        "stat_functions = list(statistics.values())\n",
        "\n",
        "def generate_statistics(wave):\n",
        "    \"\"\"\n",
        "    Generates the globally defined statistics* about a given wave (* see variable 'statistics')\n",
        "\n",
        "    @param wave        : wave object\n",
        "    @type wave         : dictionary\n",
        "    @return colnames   : names of generated statistics (note: has wave_stats ordering)\n",
        "    @rtype colnames    : list\n",
        "    @return wave_stats : generated statistics (note: has colnames ordering)\n",
        "    @rtype wave_stats  : list\n",
        "    \"\"\"\n",
        "    stats = {}\n",
        "    Y = wave['y']\n",
        "    i=0\n",
        "    for fun in stat_functions:\n",
        "        dic = fun(Y)\n",
        "        #print(dic)\n",
        "        try:\n",
        "            for k,v in dic.items():\n",
        "                stats[k] = v\n",
        "        except:\n",
        "            if (i == 0):\n",
        "                stats[\"mean\"] = dic\n",
        "                i+=1\n",
        "            else:\n",
        "                stats[\"stdev\"] = dic\n",
        "                \n",
        "    colnames = list(stats.keys())\n",
        "    wave_stats = list(stats.values())\n",
        "    return colnames, wave_stats\n",
        "\n",
        "def predict(wave, classifier, standard_scaler):\n",
        "    colnames, wave_stats = generate_statistics(wave)\n",
        "    # get rid of nan values\n",
        "    #wave_stats[np.isnan(wave_stats)] = 0\n",
        "    wave_stats_reshape = np.reshape(wave_stats, (1,-1))\n",
        "    # create a dataframe\n",
        "    wave_stats_dataframe = pd.DataFrame(wave_stats_reshape, columns = colnames)\n",
        "    # select specific stats\n",
        "    wave_stats = wave_stats_dataframe[['flat_spots', 'crossing_points', 'diff2_acf10', 'stdev']]\n",
        "    # just the values in an array\n",
        "    wave_stats = np.array(wave_stats.values)\n",
        "    # normalise\n",
        "\n",
        "    wave_stats = standard_scaler.transform(wave_stats)\n",
        "    # predict.\n",
        "    label = classifier.predict(wave_stats)\n",
        "    return label\n",
        "\n",
        "\n",
        "wave_types = [\"waves\", \"filtered\"]\n",
        "classifiers = [\"simple\"]\n",
        "data_path = \"new_training_data/spiker_\"\n",
        "\n",
        "for wave_type in wave_types:\n",
        "\n",
        "    # running accuracy test             \n",
        "\n",
        "    for classifier_type in classifiers:\n",
        "        print(f'TESTING ACCURACY for {wave_type if wave_type == \"filtered\" else \"unfiltered\"} waves with {classifier_type} classifier...')\n",
        "\n",
        "        actual_labels = get_actual_labels(f\"{data_path}{wave_type}\", classifier = classifier_type)\n",
        "\n",
        "        predicted_labels = simple_prediction(f\"{data_path}{wave_type}\")\n",
        "\n",
        "        # print(f\"Actual labels: {actual_labels}\")\n",
        "        # print(f\"Predicted labels: {predicted_labels}\")\n",
        "\n",
        "        if len(actual_labels) != len(predicted_labels):\n",
        "            print(\"ERROR\")\n",
        "            exit(1)\n",
        "\n",
        "        #confusion matrix building\n",
        "\n",
        "        counter = 0\n",
        "        left_correct = 0\n",
        "        right_correct = 0\n",
        "        left_wrong = 0\n",
        "        right_wrong = 0\n",
        "\n",
        "        for a,p in zip(actual_labels, predicted_labels):\n",
        "            if a == p:\n",
        "                counter += 1\n",
        "            if a == \"0\" and p == \"0\":\n",
        "                left_correct += 1\n",
        "            if a == \"1\" and p == \"1\":\n",
        "                right_correct += 1\n",
        "            if a == \"0\" and p == \"1\":\n",
        "                left_wrong += 1\n",
        "            if a == \"1\" and p == \"0\":\n",
        "                right_wrong += 1\n",
        "\n",
        "        print(\"   | PL | PR\")\n",
        "        print(\"==\"*11)\n",
        "        print(f\"TL | {left_correct} | {left_wrong}\")\n",
        "        print(f\"TR | {right_wrong} | {right_correct}\")\n",
        "\n",
        "        print(\"Accuracy: {:0.2f}%\\n\".format( (counter/len(actual_labels))*100) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TESTING ACCURACY for unfiltered waves with simple classifier...\n",
            "   | PL | PR\n",
            "======================\n",
            "TL | 43 | 13\n",
            "TR | 14 | 39\n",
            "Accuracy: 75.23%\n",
            "\n",
            "TESTING ACCURACY for filtered waves with simple classifier...\n",
            "   | PL | PR\n",
            "======================\n",
            "TL | 19 | 37\n",
            "TR | 31 | 22\n",
            "Accuracy: 37.61%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE4rEh0Kwn3n",
        "outputId": "0aaa3db1-312e-4d29-b4f7-1bf54cde2be7"
      },
      "source": [
        "####### error calculation - unfiltered waves simple classifier ####\n",
        "####### uses confusion matrix results above #######################\n",
        "import numpy as np\n",
        "correct = np.ones(82)\n",
        "inc = np.zeros(27)\n",
        "all = np.append(correct,inc)\n",
        "np.std(list(all))/np.sqrt(len(all))*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.13474814814058"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj51AWepxXZd",
        "outputId": "a6ea60cd-528e-4db7-8828-1165de5b930f"
      },
      "source": [
        "####### error calculation - unfiltered waves simple classifier ####\n",
        "import numpy as np\n",
        "correct = np.ones(41)\n",
        "inc = np.zeros(68)\n",
        "all = np.append(correct,inc)\n",
        "np.std(list(all))/np.sqrt(len(all))*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.639878815669915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4ZiC40tErIQ"
      },
      "source": [
        "## Appendix F \n",
        "\n",
        "*Code to produce the mircophone amplitude detector accuracy using pre-recorded data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B5VfhlPE1wm"
      },
      "source": [
        "audio_folder = \"training_data/audio_waves/\"\n",
        "#audio_filename = \"mic_recording_\" + start_time + \"_\" + recording_type + \".wav\"\n",
        "\n",
        "directory_list = os.listdir(audio_folder)\n",
        "\n",
        "test_outcomes = []\n",
        "latencies = []\n",
        "\n",
        "for filename in directory_list:\n",
        "    if filename[len(filename)-9:] == \"shoot.wav\":\n",
        "        # no shoot tests\n",
        "        if filename[len(filename)-12:] == \"no_shoot.wav\":\n",
        "            # read wavfile\n",
        "            samplerate, data = wavfile.read(audio_folder + \"/\" + filename)\n",
        "            # should give a negative (0)\n",
        "            test_passed = not if_amplitude_over(data, 0.1)\n",
        "            test_outcomes.append(test_passed)\n",
        "\n",
        "        # positive shoot tests\n",
        "        else:\n",
        "            # read wavfile\n",
        "            samplerate, data = wavfile.read(audio_folder + \"/\" + filename)\n",
        "            test_passed = if_amplitude_over(data, 0.1)\n",
        "            test_outcomes.append(test_passed)\n",
        "\n",
        "accuracy = np.mean(test_outcomes)*100\n",
        "SEM = (np.std(test_outcomes)/np.sqrt(len(test_outcomes)))*100\n",
        "print(\"Accuracy of amplitude detector is: {} +/- {}%\".format(accuracy, SEM))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
